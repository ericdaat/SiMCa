{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Function\n",
    "from torchviz import make_dot\n",
    "\n",
    "from src.ml.sinkhorn import pot_sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 512\n",
    "n_clusters = 128\n",
    "batch_size = 64\n",
    "n_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, n_features, n_clusters, n_samples):\n",
    "        self.n_features = n_features\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_samples = n_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_true[idx]\n",
    "    \n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(\n",
    "            nrows=1,\n",
    "            ncols=1,\n",
    "            figsize=(5, 5)\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(  # plot first 2 components\n",
    "            x=self.X[:, 0],\n",
    "            y=self.X[:, 1],\n",
    "            hue=map(str, self.y_true),\n",
    "            ax=ax,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Component 1\")\n",
    "        ax.set_ylabel(\"Component 2\")\n",
    "        ax.set_title(\"Clusters visualization\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "\n",
    "class BlobsDataset(ToyDataset):\n",
    "    \"\"\"\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_clusters, n_samples):\n",
    "        super().__init__(n_features, n_clusters, n_samples)\n",
    "        \n",
    "        X, y_true = make_blobs(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            centers=n_clusters,\n",
    "            cluster_std=.8,\n",
    "            random_state=0\n",
    "        )\n",
    "        \n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y_true = torch.LongTensor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BlobsDataset(n_features, n_clusters, n_samples)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        mlp_out = self.mlp(inputs)\n",
    "        softmax_out = nn.LogSoftmax(dim=1)(mlp_out)\n",
    "        \n",
    "        return softmax_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue implementation\n",
    "\n",
    "- [x] stored_M (= previous batchs dans la queue)\n",
    "- [x] M = current batch\n",
    "- [x] tu rajoutes stored_M comme argument supplementaire à SinkhornValueFunc\n",
    "- [x] sinkhorn est execute sur M_full = concatenation de M et stored_M\n",
    "- [x] puis dans SinkhornValue tu implemente la logique de storer les M quand tu call la fonction, avec une logique de queue FIFO \n",
    "- [x] et pas besoin d'utiliser une queue pour cela, juste un tensor me semble suffisant, juste quand tu arrives à la limite de taille, pour inserer le nouveau batch, tu \"roll\" le tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    input_dim=n_features,\n",
    "    output_dim=n_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/Code/virtualenvs/data-science/lib/python3.7/site-packages/ot/bregman.py:723: UserWarning: Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.\n",
      "  warnings.warn(\"Sinkhorn did not converge. You might want to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: torch.Size([64, 128])\n",
      "Batch 1: torch.Size([128, 128])\n",
      "Batch 2: torch.Size([128, 128])\n",
      "Batch 3: torch.Size([128, 128])\n",
      "Batch 4: torch.Size([128, 128])\n",
      "Batch 5: torch.Size([128, 128])\n",
      "Batch 6: torch.Size([128, 128])\n",
      "Batch 7: torch.Size([128, 128])\n",
      "Batch 8: torch.Size([128, 128])\n",
      "Batch 9: torch.Size([128, 128])\n",
      "Batch 10: torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "stored_M = torch.Tensor()   # tensor acts as queue\n",
    "max_n_batches_in_queue = 2  # max number of batches in queue\n",
    "\n",
    "for batch_ix, (inputs, labels) in enumerate(dataloader):\n",
    "    # M is model output\n",
    "    M = model(nn.functional.normalize(inputs))\n",
    "    \n",
    "    #################\n",
    "    # Sinkhorn step #\n",
    "    #################\n",
    "    M_concat = torch.cat([M, stored_M])\n",
    "    \n",
    "    # Compute marginals\n",
    "    a = torch.ones(M_concat.shape[0])\n",
    "    b = torch.ones(M_concat.shape[1]) * (M.shape[0] / M.shape[1])\n",
    "    \n",
    "    # Compute sinkhorn\n",
    "    P = pot_sinkhorn(M_concat, a, b, epsilon=0.1, method=\"sinkhorn_log\")\n",
    "\n",
    "    ################ \n",
    "    # Update queue #\n",
    "    ################\n",
    "    \n",
    "    if max_n_batches_in_queue > 0:\n",
    "        # Update stored M\n",
    "        n_batches_in_queue = stored_M.shape[0] / batch_size\n",
    "        if  n_batches_in_queue < max_n_batches_in_queue:\n",
    "            # Append current batch to previous batches\n",
    "            stored_M = M_concat\n",
    "        else:\n",
    "            # Roll stored M, older batch comes first, replace it with M\n",
    "            stored_M = torch.roll(stored_M, batch_size, 0)  # roll, first batch is the oldest\n",
    "            stored_M[:batch_size, :] = M                    # update first batch with new one\n",
    "    \n",
    "    # Print for debug\n",
    "    print(\"Batch {0}: {1}\".format(batch_ix, stored_M.shape))\n",
    "    \n",
    "    if batch_ix == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornValueFunc(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, M, stored_M, a, b, epsilon, solver, solver_options):\n",
    "        # Concat M and stored_M from the queue\n",
    "        # Note: stored_M is empty when the queue is ignored\n",
    "        #       in this case, M_concat = M\n",
    "        M_concat = torch.cat([M, stored_M])\n",
    "\n",
    "        # Run Sinkhorn on concatenation between M and queue\n",
    "        P = solver(\n",
    "            M_concat.detach(),\n",
    "            a,\n",
    "            b,\n",
    "            epsilon,\n",
    "            **solver_options\n",
    "        )\n",
    "\n",
    "        # Take only P rows from current batch\n",
    "        P = P[:M.shape[0], :]\n",
    "\n",
    "        log_P = P.log().clamp(min=-100)\n",
    "        H = - (P * log_P).sum()\n",
    "        value_OT = (P*M).sum() - epsilon*H\n",
    "\n",
    "        ctx.save_for_backward(P)\n",
    "        return value_OT\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        P, = ctx.saved_tensors\n",
    "        grad_M = P * grad_output\n",
    "\n",
    "        return grad_M, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "class SinkhornValue(nn.Module):\n",
    "    \"\"\"Sinkhorn value.\n",
    "\n",
    "    Returns optimal value for the regularized OT problem:\n",
    "        L(M) = min <M, P> - \\epsilon H[P] s.t. \\sum_j P_ij = a_i and \\sum_i P_ij = b_j\n",
    "    with entropy H[P] = - \\sum_ij P_ij log(P_ij)\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): regularization parameter\n",
    "        solver (function): OT solver\n",
    "        solver_kwargs (int): options to pass to the solver\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon, max_n_batches_in_queue, solver,\n",
    "                 **solver_options):\n",
    "        super().__init__()\n",
    "        # Sinkhorn params\n",
    "        self.epsilon = epsilon\n",
    "        self.solver = solver\n",
    "        self.solver_options = solver_options\n",
    "\n",
    "        # Queue params\n",
    "        self.stored_M = torch.Tensor().to(device)  # tensor acts as queue\n",
    "        # Maximum number of batches to store in queue, set to 0 for no queue\n",
    "        self.max_n_batches_in_queue = max_n_batches_in_queue\n",
    "\n",
    "    def forward(self, M):\n",
    "        batch_size = M.shape[0]\n",
    "        M = M.to(device)\n",
    "\n",
    "        #################\n",
    "        # Sinkhorn step #\n",
    "        #################\n",
    "        # Compute marginals\n",
    "        with torch.no_grad():\n",
    "            M_concat = torch.cat([M, self.stored_M]).to(device)\n",
    "            # a has batch_size len\n",
    "            a = torch.ones(M_concat.shape[0]).to(device)\n",
    "            # b has n_clusters len\n",
    "            b = (torch.ones(M_concat.shape[1]) * (M_concat.shape[0] / M_concat.shape[1])).to(device)\n",
    "\n",
    "        # Compute sinkhorn\n",
    "        loss = SinkhornValueFunc.apply(\n",
    "            M,                   # current batch M\n",
    "            self.stored_M,       # M stored in queue\n",
    "            a,                   # batch size marginal\n",
    "            b,                   # cluster size marginal\n",
    "            self.epsilon,        # sinkhorn entropy\n",
    "            self.solver,         # sinkhorn solver\n",
    "            self.solver_options  # sinkhorn solver options\n",
    "        )\n",
    "\n",
    "        # if queue len > 0, use the queue, otherwise don't\n",
    "        if self.max_n_batches_in_queue > 0:\n",
    "            ################\n",
    "            # Update queue #\n",
    "            ################\n",
    "            with torch.no_grad():\n",
    "                # get current number of batches in queue\n",
    "                n_batches_in_queue = self.stored_M.shape[0] / batch_size\n",
    "\n",
    "                # if current n batches < max batches\n",
    "                if n_batches_in_queue < self.max_n_batches_in_queue:\n",
    "                    # Append current batch to previous batches\n",
    "                    self.stored_M = M_concat\n",
    "                else:\n",
    "                    # Roll stored M by a batch size\n",
    "                    self.stored_M = torch.roll(self.stored_M, batch_size, 0)\n",
    "                    # Oldest batch is now first, replace it with current M\n",
    "                    self.stored_M[:batch_size, :] = M\n",
    "\n",
    "        # return loss value on current M\n",
    "        return loss\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            f\"epsilon={self.epsilon:.2e}, solver={self.solver},\"\n",
    "            \"solver_options={self.solver_options}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Model(\n",
    "    input_dim=n_features,\n",
    "    output_dim=n_clusters\n",
    ")\n",
    "assert model.mlp[0].in_features == n_features\n",
    "assert model.mlp[-1].out_features == n_clusters\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Define loss\n",
    "SV = SinkhornValue(\n",
    "    epsilon=.2,\n",
    "    solver=pot_sinkhorn,\n",
    "    max_n_batches_in_queue=2,\n",
    "    method=\"sinkhorn_log\",\n",
    "    numItermax=100,\n",
    "    warn=True\n",
    ")\n",
    "assert SV.solver == pot_sinkhorn\n",
    "assert SV.solver_options.get(\"method\") == \"sinkhorn_log\"\n",
    "assert SV.solver_options.get(\"numItermax\") == 100\n",
    "assert SV.solver_options.get(\"warn\") == True\n",
    "assert isinstance(SV.stored_M, torch.Tensor)\n",
    "assert SV.stored_M.shape[0] == 0\n",
    "\n",
    "\n",
    "# Input data\n",
    "X, y = next(iter(dataloader))\n",
    "X_norm = nn.functional.normalize(X)\n",
    "assert X_norm.shape == (batch_size, n_features)\n",
    "assert round(torch.norm(X_norm[1]).item(), ndigits=4) == 1.\n",
    "assert y.shape[0] == batch_size\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "optimizer.zero_grad()\n",
    "M = model(X_norm)\n",
    "assert M.shape == (batch_size, n_clusters)\n",
    "assert all(torch.round(torch.exp(M).sum(axis=1)) == 1.)\n",
    "assert torch.exp(M).min() >= 0\n",
    "assert torch.exp(M).max() <= 1\n",
    "\n",
    "\n",
    "# Marginals\n",
    "a = torch.ones(M.shape[0])\n",
    "b = torch.ones(M.shape[1]) * (M.shape[0] / M.shape[1])\n",
    "assert a.shape[0] == batch_size\n",
    "assert all(a == torch.ones(batch_size))\n",
    "assert b.shape[0] == n_clusters\n",
    "assert all(b == batch_size / n_clusters)\n",
    "\n",
    "\n",
    "# Sinkhorn solver\n",
    "P = pot_sinkhorn(M=-M, a=a, b=b, epsilon=SV.epsilon, **SV.solver_options)\n",
    "assert all(np.round(P.sum(axis=1).data.numpy(), 2) == 1.)\n",
    "assert all(np.round(P.sum(axis=0).data.numpy(), 2) == 0.5)\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "log_P = P.log().clamp(min=-100)\n",
    "H = - (P * log_P).sum()\n",
    "value_OT = (P*-M).sum() - SV.epsilon*H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(310.5510, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P*-M).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (20211204.2007)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"339pt\" height=\"468pt\"\n",
       " viewBox=\"0.00 0.00 339.00 468.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 464)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-464 335,-464 335,4 -4,4\"/>\n",
       "<!-- 5061582288 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5061582288</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"205,-31 128,-31 128,0 205,0 205,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (64, 128)</text>\n",
       "</g>\n",
       "<!-- 5062014608 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5062014608</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-86 101,-86 101,-67 232,-67 232,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n",
       "</g>\n",
       "<!-- 5062014608&#45;&gt;5061582288 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>5062014608&#45;&gt;5061582288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-66.79C166.5,-60.07 166.5,-50.4 166.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-41.19 166.5,-31.19 163,-41.19 170,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5062016912 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5062016912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-141 116,-141 116,-122 217,-122 217,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 5062016912&#45;&gt;5062014608 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5062016912&#45;&gt;5062014608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-121.75C166.5,-114.8 166.5,-104.85 166.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-96.09 166.5,-86.09 163,-96.09 170,-96.09\"/>\n",
       "</g>\n",
       "<!-- 5062014544 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5062014544</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5062014544&#45;&gt;5062016912 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5062014544&#45;&gt;5062016912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.14,-176.98C87.8,-168.46 116.75,-155.23 138.24,-145.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.88,-148.51 147.52,-141.17 136.97,-142.14 139.88,-148.51\"/>\n",
       "</g>\n",
       "<!-- 5061764016 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5061764016</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"89,-262 12,-262 12,-232 89,-232 89,-262\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">mlp.2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 5061764016&#45;&gt;5062014544 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5061764016&#45;&gt;5062014544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.84C50.5,-224.21 50.5,-214.7 50.5,-206.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.27 50.5,-196.27 47,-206.27 54,-206.27\"/>\n",
       "</g>\n",
       "<!-- 5062013008 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5062013008</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-196 119,-196 119,-177 214,-177 214,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 5062013008&#45;&gt;5062016912 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5062013008&#45;&gt;5062016912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-176.75C166.5,-169.8 166.5,-159.85 166.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-151.09 166.5,-141.09 163,-151.09 170,-151.09\"/>\n",
       "</g>\n",
       "<!-- 5051005328 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5051005328</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"212,-256.5 111,-256.5 111,-237.5 212,-237.5 212,-256.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"161.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 5051005328&#45;&gt;5062013008 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5051005328&#45;&gt;5062013008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.24,-237.37C162.93,-229.25 164,-216.81 164.89,-206.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.39,-206.43 165.76,-196.17 161.42,-205.83 168.39,-206.43\"/>\n",
       "</g>\n",
       "<!-- 5053110864 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5053110864</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114,-322.5 13,-322.5 13,-303.5 114,-303.5 114,-322.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5053110864&#45;&gt;5051005328 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5053110864&#45;&gt;5051005328</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.72,-303.37C92.86,-292.82 120.41,-274.84 139.71,-262.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"141.72,-265.1 148.18,-256.7 137.89,-259.24 141.72,-265.1\"/>\n",
       "</g>\n",
       "<!-- 5061764400 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5061764400</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"102,-394 25,-394 25,-364 102,-364 102,-394\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">mlp.0.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"63.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 5061764400&#45;&gt;5053110864 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5061764400&#45;&gt;5053110864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.5,-363.8C63.5,-354.7 63.5,-342.79 63.5,-332.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67,-332.84 63.5,-322.84 60,-332.84 67,-332.84\"/>\n",
       "</g>\n",
       "<!-- 5053110032 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5053110032</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"209,-322.5 132,-322.5 132,-303.5 209,-303.5 209,-322.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5053110032&#45;&gt;5051005328 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5053110032&#45;&gt;5051005328</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.29,-303.37C167.98,-294.07 165.86,-278.98 164.16,-266.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.61,-266.32 162.75,-256.91 160.68,-267.3 167.61,-266.32\"/>\n",
       "</g>\n",
       "<!-- 5053108432 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5053108432</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"221,-388.5 120,-388.5 120,-369.5 221,-369.5 221,-388.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.5\" y=\"-376.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5053108432&#45;&gt;5053110032 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5053108432&#45;&gt;5053110032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.5,-369.37C170.5,-360.16 170.5,-345.29 170.5,-333.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174,-332.91 170.5,-322.91 167,-332.91 174,-332.91\"/>\n",
       "</g>\n",
       "<!-- 5061764688 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>5061764688</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"215,-460 126,-460 126,-430 215,-430 215,-460\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\">mlp.0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"170.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\"> (256, 512)</text>\n",
       "</g>\n",
       "<!-- 5061764688&#45;&gt;5053108432 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5061764688&#45;&gt;5053108432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.5,-429.8C170.5,-420.7 170.5,-408.79 170.5,-398.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174,-398.84 170.5,-388.84 167,-398.84 174,-398.84\"/>\n",
       "</g>\n",
       "<!-- 5062016592 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>5062016592</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"314,-196 237,-196 237,-177 314,-177 314,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5062016592&#45;&gt;5062016912 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5062016592&#45;&gt;5062016912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.99,-176.98C240.53,-168.5 213.49,-155.35 193.33,-145.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.86,-142.4 184.33,-141.17 191.79,-148.69 194.86,-142.4\"/>\n",
       "</g>\n",
       "<!-- 5053110992 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5053110992</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"331,-256.5 230,-256.5 230,-237.5 331,-237.5 331,-256.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5053110992&#45;&gt;5062016592 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5053110992&#45;&gt;5062016592</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.76,-237.37C279.07,-229.25 278,-216.81 277.11,-206.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.58,-205.83 276.24,-196.17 273.61,-206.43 280.58,-205.83\"/>\n",
       "</g>\n",
       "<!-- 5061765360 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>5061765360</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"325,-328 236,-328 236,-298 325,-298 325,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">mlp.2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"280.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\"> (128, 256)</text>\n",
       "</g>\n",
       "<!-- 5061765360&#45;&gt;5053110992 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5061765360&#45;&gt;5053110992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.5,-297.8C280.5,-288.7 280.5,-276.79 280.5,-266.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284,-266.84 280.5,-256.84 277,-266.84 284,-266.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12dba4d50>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computational graph\n",
    "make_dot(M, params=dict(list(model.named_parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35e7e15e99ced0a59866f00000561dd568615f64817c6500270e1aee9e906325"
  },
  "kernelspec": {
   "display_name": "Python 3 (data-science)",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
