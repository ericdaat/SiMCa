{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Function\n",
    "from torchviz import make_dot\n",
    "\n",
    "from src.ml.sinkhorn import pot_sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 512\n",
    "n_clusters = 128\n",
    "batch_size = 64\n",
    "n_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, n_features, n_clusters, n_samples):\n",
    "        self.n_features = n_features\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_samples = n_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_true[idx]\n",
    "    \n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(\n",
    "            nrows=1,\n",
    "            ncols=1,\n",
    "            figsize=(5, 5)\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(  # plot first 2 components\n",
    "            x=self.X[:, 0],\n",
    "            y=self.X[:, 1],\n",
    "            hue=map(str, self.y_true),\n",
    "            ax=ax,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Component 1\")\n",
    "        ax.set_ylabel(\"Component 2\")\n",
    "        ax.set_title(\"Clusters visualization\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "\n",
    "class BlobsDataset(ToyDataset):\n",
    "    \"\"\"\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_clusters, n_samples):\n",
    "        super().__init__(n_features, n_clusters, n_samples)\n",
    "        \n",
    "        X, y_true = make_blobs(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            centers=n_clusters,\n",
    "            cluster_std=.8,\n",
    "            random_state=0\n",
    "        )\n",
    "        \n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y_true = torch.LongTensor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BlobsDataset(n_features, n_clusters, n_samples)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        mlp_out = self.mlp(inputs)\n",
    "        softmax_out = nn.LogSoftmax(dim=1)(mlp_out)\n",
    "        \n",
    "        return softmax_out\n",
    "    \n",
    "model = Model(\n",
    "    input_dim=n_features,\n",
    "    output_dim=n_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue implementation\n",
    "\n",
    "- [x] stored_M (= previous batchs dans la queue)\n",
    "- [x] M = current batch\n",
    "- [x] tu rajoutes stored_M comme argument supplementaire à SinkhornValueFunc\n",
    "- [x] sinkhorn est execute sur M_full = concatenation de M et stored_M\n",
    "- [ ] puis dans SinkhornValue tu implemente la logique de storer les M quand tu call la fonction, avec une logique de queue FIFO \n",
    "- [x] et pas besoin d'utiliser une queue pour cela, juste un tensor me semble suffisant, juste quand tu arrives à la limite de taille, pour inserer le nouveau batch, tu \"roll\" le tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/Code/virtualenvs/data-science/lib/python3.7/site-packages/ot/bregman.py:723: UserWarning: Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.\n",
      "  warnings.warn(\"Sinkhorn did not converge. You might want to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: torch.Size([64, 128])\n",
      "Batch 1: torch.Size([128, 128])\n",
      "Batch 2: torch.Size([192, 128])\n",
      "Batch 3: torch.Size([256, 128])\n",
      "Batch 4: torch.Size([256, 128])\n",
      "Batch 5: torch.Size([256, 128])\n",
      "Batch 6: torch.Size([256, 128])\n",
      "Batch 7: torch.Size([256, 128])\n",
      "Batch 8: torch.Size([256, 128])\n",
      "Batch 9: torch.Size([256, 128])\n",
      "Batch 10: torch.Size([256, 128])\n"
     ]
    }
   ],
   "source": [
    "stored_M = torch.Tensor()   # tensor acts as queue\n",
    "max_n_batches_in_queue = 4  # max number of batches in queue\n",
    "\n",
    "for batch_ix, (inputs, labels) in enumerate(dataloader):\n",
    "    # M is model output\n",
    "    M = model(inputs)\n",
    "    \n",
    "    #################\n",
    "    # Sinkhorn step #\n",
    "    #################\n",
    "    \n",
    "    M_concat = torch.cat([M, stored_M])\n",
    "    \n",
    "    # Compute marginals\n",
    "    a = torch.ones(M_concat.shape[0])\n",
    "    b = torch.ones(M_concat.shape[1]) * (M.shape[0] / M.shape[1])\n",
    "    \n",
    "    # Compute sinkhorn\n",
    "    P = pot_sinkhorn(M_concat, a, b, epsilon=0.1)\n",
    "\n",
    "    ################ \n",
    "    # Update queue #\n",
    "    ################\n",
    "    \n",
    "    # Update stored M\n",
    "    n_batches_in_queue = stored_M.shape[0] / batch_size\n",
    "    if  n_batches_in_queue < max_n_batches_in_queue:\n",
    "        # Append current batch to previous batches\n",
    "        stored_M = M_concat\n",
    "    else:\n",
    "        # Roll stored M, older batch comes first, replace it with M\n",
    "        stored_M = torch.roll(stored_M, batch_size, 0)  # roll, first batch is the oldest\n",
    "        stored_M[:batch_size, :] = M                    # update first batch with new one\n",
    "    \n",
    "    # Print for debug\n",
    "    print(\"Batch {0}: {1}\".format(batch_ix, stored_M.shape))\n",
    "    \n",
    "    if batch_ix == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornValueFunc(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, M, stored_M, a, b, epsilon, solver, solver_options):\n",
    "        # Run Sinkhorn\n",
    "        P = solver(\n",
    "            torch.cat([M, stored_M]).detach(),  # Use the queue\n",
    "            a,\n",
    "            b,\n",
    "            epsilon,\n",
    "            **solver_options\n",
    "        )\n",
    "        P = P[:M.shape[0], :]  # Take only current batch\n",
    "\n",
    "        ctx.save_for_backward(P)\n",
    "        return (P*M).sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        P, = ctx.saved_tensors\n",
    "        grad_M = P * grad_output\n",
    "\n",
    "        return grad_M, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "class SinkhornValue(nn.Module):\n",
    "    \"\"\"Sinkhorn value.\n",
    "\n",
    "    Returns optimal value for the regularized OT problem:\n",
    "        L(M) = max <M, P> + \\epsilon H[P] s.t. \\sum_j P_ij = a_i and \\sum_i P_ij = b_j\n",
    "    with entropy H[P] = - \\sum_ij P_ij [log(P_ij) - 1]\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): regularization parameter\n",
    "        solver (function): OT solver\n",
    "        solver_kwargs (int): options to pass to the solver\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon, max_n_batches_in_queue, solver,\n",
    "                 **solver_options):\n",
    "        super().__init__()\n",
    "        # Sinkhorn params\n",
    "        self.epsilon = epsilon\n",
    "        self.solver = solver\n",
    "        self.solver_options = solver_options\n",
    "\n",
    "        # Queue params\n",
    "        self.stored_M = torch.Tensor().to(device)  # tensor acts as queue\n",
    "        self.max_n_batches_in_queue = max_n_batches_in_queue\n",
    "\n",
    "    def forward(self, M):\n",
    "        batch_size = M.shape[0]\n",
    "        M = M.to(device)\n",
    "\n",
    "        #################\n",
    "        # Sinkhorn step #\n",
    "        #################\n",
    "        # Compute marginals\n",
    "        with torch.no_grad():\n",
    "            M_concat = torch.cat([M, self.stored_M]).to(device)\n",
    "            a = torch.ones(M_concat.shape[0]).to(device)\n",
    "            b = (torch.ones(M_concat.shape[1]) / (M_concat.shape[0] / M_concat.shape[1])).to(device)\n",
    "\n",
    "        # Compute sinkhorn\n",
    "        loss = SinkhornValueFunc.apply(\n",
    "            M,\n",
    "            self.stored_M,\n",
    "            a,\n",
    "            b,\n",
    "            self.epsilon,\n",
    "            self.solver,\n",
    "            self.solver_options\n",
    "        )\n",
    "\n",
    "        ################\n",
    "        # Update queue #\n",
    "        ################\n",
    "        with torch.no_grad():\n",
    "            n_batches_in_queue = self.stored_M.shape[0] / batch_size\n",
    "            if n_batches_in_queue < self.max_n_batches_in_queue:\n",
    "                # Append current batch to previous batches\n",
    "                self.stored_M = M_concat\n",
    "            else:\n",
    "                # Roll stored M, older batch comes first, replace it with M\n",
    "                self.stored_M = torch.roll(self.stored_M, batch_size, 0)\n",
    "                self.stored_M[:batch_size, :] = M\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            f\"epsilon={self.epsilon:.2e}, solver={self.solver},\"\n",
    "            \"solver_options={self.solver_options}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = SinkhornValue(\n",
    "    epsilon=0.1,\n",
    "    solver=pot_sinkhorn,\n",
    "    max_n_batches_in_queue=4\n",
    ")\n",
    "\n",
    "for batch_ix, (inputs, labels) in enumerate(dataloader):\n",
    "    M = model(inputs)\n",
    "    \n",
    "    loss = SV(-M)\n",
    "    \n",
    "    # loss.backward()\n",
    "    \n",
    "    if batch_ix == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (20211204.2007)\n -->\n<!-- Pages: 1 -->\n<svg width=\"339pt\" height=\"590pt\"\n viewBox=\"0.00 0.00 339.00 590.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 586)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-586 335,-586 335,4 -4,4\"/>\n<!-- 4971213360 -->\n<g id=\"node1\" class=\"node\">\n<title>4971213360</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"243.5,-31 189.5,-31 189.5,0 243.5,0 243.5,-31\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 5008658512 -->\n<g id=\"node2\" class=\"node\">\n<title>5008658512</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"300,-86 133,-86 133,-67 300,-67 300,-86\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SinkhornValueFuncBackward</text>\n</g>\n<!-- 5008658512&#45;&gt;4971213360 -->\n<g id=\"edge17\" class=\"edge\">\n<title>5008658512&#45;&gt;4971213360</title>\n<path fill=\"none\" stroke=\"black\" d=\"M216.5,-66.79C216.5,-60.07 216.5,-50.4 216.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"220,-41.19 216.5,-31.19 213,-41.19 220,-41.19\"/>\n</g>\n<!-- 5006781584 -->\n<g id=\"node3\" class=\"node\">\n<title>5006781584</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"211,-147 122,-147 122,-128 211,-128 211,-147\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-135\" font-family=\"monospace\" font-size=\"10.00\">NegBackward0</text>\n</g>\n<!-- 5006781584&#45;&gt;5008658512 -->\n<g id=\"edge1\" class=\"edge\">\n<title>5006781584&#45;&gt;5008658512</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173.88,-127.79C181.41,-118.91 193.29,-104.89 202.59,-93.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"205.3,-96.13 209.09,-86.24 199.96,-91.61 205.3,-96.13\"/>\n</g>\n<!-- 5006780816 -->\n<g id=\"node4\" class=\"node\">\n<title>5006780816</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-208 101,-208 101,-189 232,-189 232,-208\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-196\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n</g>\n<!-- 5006780816&#45;&gt;5006781584 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5006780816&#45;&gt;5006781584</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.5,-188.79C166.5,-180.6 166.5,-168.06 166.5,-157.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170,-157.24 166.5,-147.24 163,-157.24 170,-157.24\"/>\n</g>\n<!-- 5006780624 -->\n<g id=\"node5\" class=\"node\">\n<title>5006780624</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-263 116,-263 116,-244 217,-244 217,-263\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 5006780624&#45;&gt;5006780816 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5006780624&#45;&gt;5006780816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.5,-243.75C166.5,-236.8 166.5,-226.85 166.5,-218.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170,-218.09 166.5,-208.09 163,-218.09 170,-218.09\"/>\n</g>\n<!-- 5008853328 -->\n<g id=\"node6\" class=\"node\">\n<title>5008853328</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-318 0,-318 0,-299 101,-299 101,-318\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 5008853328&#45;&gt;5006780624 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5008853328&#45;&gt;5006780624</title>\n<path fill=\"none\" stroke=\"black\" d=\"M69.14,-298.98C87.8,-290.46 116.75,-277.23 138.24,-267.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"139.88,-270.51 147.52,-263.17 136.97,-264.14 139.88,-270.51\"/>\n</g>\n<!-- 5009464208 -->\n<g id=\"node7\" class=\"node\">\n<title>5009464208</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"89,-384 12,-384 12,-354 89,-354 89,-384\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-372\" font-family=\"monospace\" font-size=\"10.00\">mlp.2.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\"> (128)</text>\n</g>\n<!-- 5009464208&#45;&gt;5008853328 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5009464208&#45;&gt;5008853328</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-353.84C50.5,-346.21 50.5,-336.7 50.5,-328.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-328.27 50.5,-318.27 47,-328.27 54,-328.27\"/>\n</g>\n<!-- 5006780560 -->\n<g id=\"node8\" class=\"node\">\n<title>5006780560</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-318 119,-318 119,-299 214,-299 214,-318\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 5006780560&#45;&gt;5006780624 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5006780560&#45;&gt;5006780624</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.5,-298.75C166.5,-291.8 166.5,-281.85 166.5,-273.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170,-273.09 166.5,-263.09 163,-273.09 170,-273.09\"/>\n</g>\n<!-- 5006782032 -->\n<g id=\"node9\" class=\"node\">\n<title>5006782032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"212,-378.5 111,-378.5 111,-359.5 212,-359.5 212,-378.5\"/>\n<text text-anchor=\"middle\" x=\"161.5\" y=\"-366.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 5006782032&#45;&gt;5006780560 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5006782032&#45;&gt;5006780560</title>\n<path fill=\"none\" stroke=\"black\" d=\"M162.24,-359.37C162.93,-351.25 164,-338.81 164.89,-328.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"168.39,-328.43 165.76,-318.17 161.42,-327.83 168.39,-328.43\"/>\n</g>\n<!-- 5004179536 -->\n<g id=\"node10\" class=\"node\">\n<title>5004179536</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114,-444.5 13,-444.5 13,-425.5 114,-425.5 114,-444.5\"/>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-432.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 5004179536&#45;&gt;5006782032 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5004179536&#45;&gt;5006782032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M76.72,-425.37C92.86,-414.82 120.41,-396.84 139.71,-384.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141.72,-387.1 148.18,-378.7 137.89,-381.24 141.72,-387.1\"/>\n</g>\n<!-- 5009464112 -->\n<g id=\"node11\" class=\"node\">\n<title>5009464112</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"102,-516 25,-516 25,-486 102,-486 102,-516\"/>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-504\" font-family=\"monospace\" font-size=\"10.00\">mlp.0.bias</text>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-493\" font-family=\"monospace\" font-size=\"10.00\"> (256)</text>\n</g>\n<!-- 5009464112&#45;&gt;5004179536 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5009464112&#45;&gt;5004179536</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.5,-485.8C63.5,-476.7 63.5,-464.79 63.5,-454.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"67,-454.84 63.5,-444.84 60,-454.84 67,-454.84\"/>\n</g>\n<!-- 5006782160 -->\n<g id=\"node12\" class=\"node\">\n<title>5006782160</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"209,-444.5 132,-444.5 132,-425.5 209,-425.5 209,-444.5\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-432.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 5006782160&#45;&gt;5006782032 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5006782160&#45;&gt;5006782032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.29,-425.37C167.98,-416.07 165.86,-400.98 164.16,-388.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167.61,-388.32 162.75,-378.91 160.68,-389.3 167.61,-388.32\"/>\n</g>\n<!-- 5006800080 -->\n<g id=\"node13\" class=\"node\">\n<title>5006800080</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"221,-510.5 120,-510.5 120,-491.5 221,-491.5 221,-510.5\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-498.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 5006800080&#45;&gt;5006782160 -->\n<g id=\"edge11\" class=\"edge\">\n<title>5006800080&#45;&gt;5006782160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-491.37C170.5,-482.16 170.5,-467.29 170.5,-455.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-454.91 170.5,-444.91 167,-454.91 174,-454.91\"/>\n</g>\n<!-- 5009464016 -->\n<g id=\"node14\" class=\"node\">\n<title>5009464016</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"215,-582 126,-582 126,-552 215,-552 215,-582\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-570\" font-family=\"monospace\" font-size=\"10.00\">mlp.0.weight</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-559\" font-family=\"monospace\" font-size=\"10.00\"> (256, 512)</text>\n</g>\n<!-- 5009464016&#45;&gt;5006800080 -->\n<g id=\"edge12\" class=\"edge\">\n<title>5009464016&#45;&gt;5006800080</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-551.8C170.5,-542.7 170.5,-530.79 170.5,-520.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-520.84 170.5,-510.84 167,-520.84 174,-520.84\"/>\n</g>\n<!-- 5006778512 -->\n<g id=\"node15\" class=\"node\">\n<title>5006778512</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"314,-318 237,-318 237,-299 314,-299 314,-318\"/>\n<text text-anchor=\"middle\" x=\"275.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 5006778512&#45;&gt;5006780624 -->\n<g id=\"edge13\" class=\"edge\">\n<title>5006778512&#45;&gt;5006780624</title>\n<path fill=\"none\" stroke=\"black\" d=\"M257.99,-298.98C240.53,-290.5 213.49,-277.35 193.33,-267.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"194.86,-264.4 184.33,-263.17 191.79,-270.69 194.86,-264.4\"/>\n</g>\n<!-- 5008853520 -->\n<g id=\"node16\" class=\"node\">\n<title>5008853520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"331,-378.5 230,-378.5 230,-359.5 331,-359.5 331,-378.5\"/>\n<text text-anchor=\"middle\" x=\"280.5\" y=\"-366.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 5008853520&#45;&gt;5006778512 -->\n<g id=\"edge14\" class=\"edge\">\n<title>5008853520&#45;&gt;5006778512</title>\n<path fill=\"none\" stroke=\"black\" d=\"M279.76,-359.37C279.07,-351.25 278,-338.81 277.11,-328.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280.58,-327.83 276.24,-318.17 273.61,-328.43 280.58,-327.83\"/>\n</g>\n<!-- 5009463728 -->\n<g id=\"node17\" class=\"node\">\n<title>5009463728</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"325,-450 236,-450 236,-420 325,-420 325,-450\"/>\n<text text-anchor=\"middle\" x=\"280.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\">mlp.2.weight</text>\n<text text-anchor=\"middle\" x=\"280.5\" y=\"-427\" font-family=\"monospace\" font-size=\"10.00\"> (128, 256)</text>\n</g>\n<!-- 5009463728&#45;&gt;5008853520 -->\n<g id=\"edge15\" class=\"edge\">\n<title>5009463728&#45;&gt;5008853520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M280.5,-419.8C280.5,-410.7 280.5,-398.79 280.5,-388.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"284,-388.84 280.5,-378.84 277,-388.84 284,-388.84\"/>\n</g>\n<!-- 4971206608 -->\n<g id=\"node18\" class=\"node\">\n<title>4971206608</title>\n<polygon fill=\"orange\" stroke=\"black\" points=\"306,-153 229,-153 229,-122 306,-122 306,-153\"/>\n<text text-anchor=\"middle\" x=\"267.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\"> (64, 128)</text>\n</g>\n<!-- 4971206608&#45;&gt;5008658512 -->\n<g id=\"edge16\" class=\"edge\">\n<title>4971206608&#45;&gt;5008658512</title>\n<path fill=\"none\" stroke=\"black\" d=\"M254.89,-121.92C247.56,-113.43 238.3,-102.72 230.71,-93.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.25,-91.53 224.06,-86.25 227.95,-96.1 233.25,-91.53\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12a6d6d90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(loss, params=dict(list(model.named_parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35e7e15e99ced0a59866f00000561dd568615f64817c6500270e1aee9e906325"
  },
  "kernelspec": {
   "display_name": "Python 3 (data-science)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
